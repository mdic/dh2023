{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a6a6bb-62c8-4c56-843e-dd03ad2c3fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules for: regular expressions; reading timestamps as date objects; loading files using regular expression;\n",
    "# generate random numbers; reading JSONL files; working with XML files\n",
    "import re\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "import operator\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialise the Sentiment Analysis tool\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6016ad-1637-4b8b-8dc7-59fe9cb24338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all filenames with the .jsonl extension\n",
    "files = glob(\"*.jsonl\")\n",
    "\n",
    "# For each file do:\n",
    "for file in files:\n",
    "    # create an empty list to save the spreadsheet rows\n",
    "    data = []\n",
    "    output_filename = file.replace(\"*.jsonl\", \"\") + \".csv\"\n",
    "    # Read the file as a jsonlines one:\n",
    "    with jsonlines.open(file) as comments:\n",
    "        # For each line (i.e. metadata data-points for one comment) do:\n",
    "        for comment in comments:\n",
    "            # Extract the comment id ('cid') and save it to a variable\n",
    "            comment_id = str(comment[\"cid\"])\n",
    "            print(f\"Processing comment {comment_id}\")\n",
    "            # Check if the 'cid' contains a full stop character. If so, the comment is a reply to another comment: take the string on\n",
    "            # the left of the full stop and assign it as value of the attribute 'comment_id', then the string on the right and assign\n",
    "            # it as value of the attribute 'comment_reply_to' to preserve the original hierarchical structure\n",
    "            if re.search(\"(.*?)\\.(.*)\", comment_id) is not None:\n",
    "                comment_reply_to = str(\n",
    "                    re.search(\"(.*?)\\.(.*)\", comment_id).group(1)\n",
    "                )\n",
    "                comment_id = str(\n",
    "                    re.search(\"(.*?)\\.(.*)\", comment_id).group(2)\n",
    "                )\n",
    "            # If there is no full stop character, assign the 'comment_id' as value of the <comment> attribute 'comment_id' and the\n",
    "            # value 'na' to the 'comment_reply_to' attribute\n",
    "            else:\n",
    "                comment_id = comment_id\n",
    "                comment_reply_to = \"na\"\n",
    "\n",
    "            # Extract other metadata data-points and assign them to a set of variables\n",
    "            username = str(comment[\"author\"])\n",
    "            votes = str(comment[\"votes\"])\n",
    "            heart = str(comment[\"heart\"])\n",
    "            comment_timestamp = comment[\"time_parsed\"]\n",
    "            \n",
    "            # At last, get the content of the comment (the actual message)\n",
    "            comment_text = str(comment[\"text\"])\n",
    "            \n",
    "            # Calculate the sentiment of the comment, and extract the four results to four different variables\n",
    "            sa_text = analyzer.polarity_scores(comment_text)\n",
    "            negative = sa_text[\"neg\"]\n",
    "            neutral = sa_text[\"neu\"]\n",
    "            positive = sa_text[\"pos\"]\n",
    "            compound = sa_text[\"compound\"]\n",
    "            \n",
    "            # append all the extracted data to the list, formatting it as a csv line\n",
    "            data.append([comment_timestamp, comment_id, comment_reply_to, username, comment_text, negative, neutral, positive, compound])\n",
    "        \n",
    "        # after all the comments have been extracted, sort them in chronological order using their timestamps\n",
    "        data.sort(key=operator.itemgetter(0))\n",
    "        \n",
    "        # add a progressive number to the newly ordered comments, to preserve the chronological order\n",
    "        for index, element in enumerate(data, start=1):\n",
    "            element.insert(0, index)\n",
    "            \n",
    "        # create a dataframe with all the collected comments\n",
    "        csv_df = pd.DataFrame(data, columns=[\"turn\", \"comment_timestamp\", \"comment_id\", \"reply_to\", \"username\", \"comment_text\", \"negative\", \"neutral\", \"positive\", \"compound\"])\n",
    "        # write the dataframe to a csv file\n",
    "        csv_df.to_csv(output_filename, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640488f4-32b9-4b20-9255-e59bec95e71b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
